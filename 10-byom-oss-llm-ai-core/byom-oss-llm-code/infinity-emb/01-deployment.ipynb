{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7dea42f",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "This notebook illustrates and automates the Continuous Deployment process for bringing the popular open-source embedding models inference service [Infinity](https://michaelfeil.eu/infinity/latest/) into SAP AI Core. \n",
    "Subsequently, with Infinity, you can load popular sentence-transformer embedding models and frameworks (e.g. [BAAI/bge-small-en](https://huggingface.co/BAAI/bge-small-en-v1.5) into it, exposing it as a service in SAP AI Core through BYOM(Bring Your Own Model) approach. <br/>\n",
    "### Prerequisites\n",
    "Before running this notebook, please assure you have perform the [Prerequisites](../../README.md)<br/>\n",
    " \n",
    "### The high-level flow of this Continuous Deployment process:\n",
    "- Build a custom Infinity docker image adapted for SAP AI Core<br/>\n",
    "- Push the docker image to docker hub<br/>\n",
    "- Connect to SAP AI Core via SDK<br/>\n",
    "- Create a deployment<br/>\n",
    "- Check the status and logs of the deployment<br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3925c841",
   "metadata": {},
   "source": [
    "#### 1.Build a custom Infinity docker image adapted for SAP AI Core\n",
    "Please refer to [Dockerfile](Dockerfile) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42dfb1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#0 building with \"desktop-linux\" instance using docker driver\n",
      "\n",
      "#1 [internal] load build definition from Dockerfile\n",
      "#1 transferring dockerfile: 991B 0.1s\n",
      "#1 transferring dockerfile: 995B 0.1s done\n",
      "#1 DONE 0.1s\n",
      "\n",
      "#2 [internal] load metadata for docker.io/pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime\n",
      "#2 ...\n",
      "\n",
      "#3 [auth] pytorch/pytorch:pull token for registry-1.docker.io\n",
      "#3 DONE 0.0s\n",
      "\n",
      "#2 [internal] load metadata for docker.io/pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime\n",
      "#2 DONE 2.5s\n",
      "\n",
      "#4 [internal] load .dockerignore\n",
      "#4 transferring context: 2B done\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#5 [1/6] FROM docker.io/pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime@sha256:0279f7aa29974bf64e61d0ff6e979b41a249b3662a46e30778dbf80b8c99c361\n",
      "#5 resolve docker.io/pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime@sha256:0279f7aa29974bf64e61d0ff6e979b41a249b3662a46e30778dbf80b8c99c361 done\n",
      "#5 DONE 0.0s\n",
      "\n",
      "#6 [internal] load build context\n",
      "#6 transferring context: 612B 0.0s done\n",
      "#6 DONE 0.0s\n",
      "\n",
      "#7 [3/6] RUN apt-get update &&     apt-get install -y     ca-certificates     nginx     curl &&     apt-get clean &&     rm -rf /var/lib/apt/lists/*\n",
      "#7 CACHED\n",
      "\n",
      "#8 [2/6] WORKDIR /usr/src\n",
      "#8 CACHED\n",
      "\n",
      "#9 [4/6] RUN python3 -m pip install --upgrade pip==23.2.1 &&     python3 -m pip install \"infinity-emb[all]\" &&     rm -rf /root/.cache/pip\n",
      "#9 CACHED\n",
      "\n",
      "#10 [5/6] COPY run.sh /usr/src/run.sh\n",
      "#10 DONE 0.0s\n",
      "\n",
      "#11 [6/6] RUN mkdir -p /nonexistent/ &&     mkdir -p /hf-home/ &&     chown -R nobody:nogroup /nonexistent /hf-home/ &&     chmod -R 770 /nonexistent/ /hf-home/ &&     chmod +x /usr/src/run.sh\n",
      "#11 DONE 0.7s\n",
      "\n",
      "#12 exporting to image\n",
      "#12 exporting layers 0.0s done\n",
      "#12 writing image sha256:23039d51f6cd31327bd28133373558ace7edf064521e43ee980e889d53a4b846 done\n",
      "#12 naming to docker.io/jacobtan89/infinity:ai-core done\n",
      "#12 DONE 0.0s\n",
      "\n",
      "View build details: docker-desktop://dashboard/build/desktop-linux/desktop-linux/we4i95smn2suz5nhvx7wsydjb\n",
      "\n",
      "Build multi-platform images faster with Docker Build Cloud: https://docs.docker.com/go/docker-build-cloud\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "# 0.Login to docker hub\n",
    "# docker login -u <YOUR_DOCKER_USER> -p <YOUR_DOCKER_ACCESS_TOKEN>\n",
    "\n",
    "# 1.Build the docker image\n",
    "docker build --platform=linux/amd64 -t docker.io/jacobtan89/infinity:ai-core ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6081a7cf",
   "metadata": {},
   "source": [
    "#### 2.Push the docker image to docker hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa521107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [docker.io/jacobtan89/infinity]\n",
      "5c1ee1c60970: Preparing\n",
      "7d721abff97d: Preparing\n",
      "edb871e339f5: Preparing\n",
      "9d0c8bb194c1: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "23fcdddbb6de: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "36e21b1812d2: Preparing\n",
      "2d49b5c9bc32: Preparing\n",
      "e0a9f5911802: Preparing\n",
      "23fcdddbb6de: Waiting\n",
      "36e21b1812d2: Waiting\n",
      "2d49b5c9bc32: Waiting\n",
      "e0a9f5911802: Waiting\n",
      "5f70bf18a086: Mounted from jacobtan89/pytorch-infinity-model-serve\n",
      "9d0c8bb194c1: Mounted from jacobtan89/pytorch-infinity-model-serve\n",
      "edb871e339f5: Mounted from jacobtan89/pytorch-infinity-model-serve\n",
      "7d721abff97d: Pushed\n",
      "5c1ee1c60970: Pushed\n",
      "36e21b1812d2: Mounted from jacobtan89/pytorch-infinity-model-serve\n",
      "23fcdddbb6de: Mounted from jacobtan89/pytorch-infinity-model-serve\n",
      "e0a9f5911802: Mounted from jacobtan89/pytorch-infinity-model-serve\n",
      "2d49b5c9bc32: Mounted from jacobtan89/pytorch-infinity-model-serve\n",
      "ai-core: digest: sha256:f4da135a1c365d6701a36389b3e3c9f76e8fc0a9220b7e2ffdb7b095107a81e4 size: 2413\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "# 2.Push the docker image to docker hub to be used by deployment in SAP AI Core\n",
    "docker push docker.io/jacobtan89/infinity:ai-core "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9332238f",
   "metadata": {},
   "source": [
    "#### 3.Initiate an SAP AI Core SDK client\n",
    "- resource_group loaded from [../config.json](../config.json)\n",
    "- ai_core_sk(service key) loaded from [../config.json](../config.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90f1e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json, time, datetime\n",
    "from datetime import datetime\n",
    "from ai_core_sdk.ai_core_v2_client import AICoreV2Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12912738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resource group:  oss-llm\n"
     ]
    }
   ],
   "source": [
    "# load the configuration from ../config.json \n",
    "with open(\"../config.json\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "resource_group = config.get(\"resource_group\", \"default\")\n",
    "print( \"resource group: \", resource_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7654d1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate an AI Core SDK client with the information of service key\n",
    "ai_core_sk = config[\"ai_core_service_key\"]\n",
    "base_url = ai_core_sk.get(\"serviceurls\").get(\"AI_API_URL\") + \"/v2/lm\"\n",
    "client = AICoreV2Client(base_url=ai_core_sk.get(\"serviceurls\").get(\"AI_API_URL\")+\"/v2\",\n",
    "                        auth_url=ai_core_sk.get(\"url\")+\"/oauth/token\",\n",
    "                        client_id=ai_core_sk.get(\"clientid\"),\n",
    "                        client_secret=ai_core_sk.get(\"clientsecret\"),\n",
    "                        resource_group=resource_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c5b6e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the http header which will be used later through request.\n",
    "token = client.rest_client.get_token()\n",
    "headers = {\n",
    "    \"Authorization\": token,\n",
    "    \"ai-resource-group\": resource_group,\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d440ee60",
   "metadata": {},
   "source": [
    "#### 4.Create a deployment for Infinity scenario\n",
    "To create a deployment in SAP AI Core, it requires the corresponding resource_group and configuration_id\n",
    "- resource_group loaded from [../config.json](../config.json)\n",
    "- configuration_id of  loaded from [env.json](env.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "788f8134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configuration id: bb88525a-dbeb-473b-8260-c6c35afafa54\n"
     ]
    }
   ],
   "source": [
    "# resource_group: The target resource group to create the deployment\n",
    "# configuration_id: The target configuration to create the deployment, which is created in ../00-init-config.ipynb \n",
    "with open(\"./env.json\") as f:\n",
    "    env = json.load(f)\n",
    "\n",
    "configuration_id = env[\"configuration_id\"]\n",
    "print(\"configuration id:\", configuration_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728f8856",
   "metadata": {},
   "source": [
    "**Helper function**\n",
    "- get the current UTC time in yyyy-mm-dd hh:mm:ss format, to be used to filter deployments logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2c097ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get the current time in UTC, used to filter deployments logs\n",
    "def get_current_time():  \n",
    "    current_time = datetime.utcnow()\n",
    "    # Format current time in the desired format\n",
    "    formatted_time = current_time.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    return formatted_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff6ef20",
   "metadata": {},
   "source": [
    "**Helper function**\n",
    "- Write back the configuration value back to configuration json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9df6fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to write back the configuration value back to configuration json file\n",
    "def update_json_file(file_path, key, value):\n",
    "    # Load the JSON configuration file\n",
    "    with open(file_path, 'r') as file:\n",
    "        config = json.load(file)\n",
    "\n",
    "    # Update the value\n",
    "    config[key] = value\n",
    "\n",
    "    # Write the updated configuration back to the file\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(config, file, indent=4)\n",
    "        print(f\"{file_path} updated. {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e20a1a",
   "metadata": {},
   "source": [
    "**Create a deployment for Infinity in SAP AI Core**\n",
    "- configuration_id\n",
    "- resource_group\n",
    "<br/><br/>\n",
    "The created deployment id will be written back to [env.json](env.json), which will be used in\n",
    "- [01-deployment.ipynb](01-deployment.ipynb) and [02-embedding.ipynb](02-embedding.ipynb) to test the inference of open-source embedding with Infinity in SAP AI Core\n",
    "- [04-cleanup.ipynb](04-cleanup.ipynb) to stop the deployment and clean up the resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab19296d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating deployment.\n",
      "env.json updated. deployment_id: d381e0b5a1ad105f\n",
      "Deployment Result:\n",
      " {'id': 'd381e0b5a1ad105f', 'message': 'Deployment scheduled.', 'deployment_url': '', 'status': <Status.UNKNOWN: 'UNKNOWN'>, 'ttl': None}\n"
     ]
    }
   ],
   "source": [
    "# Create a Deployment in SAP AI Core\n",
    "print(\"Creating deployment.\")\n",
    "response = client.deployment.create(\n",
    "    configuration_id=configuration_id,\n",
    "    resource_group=resource_group\n",
    ")\n",
    "\n",
    "# last_check_time will be used to check the deployment status continuously afterwards\n",
    "# set initial last_check_time right after creating deployment\n",
    "last_check_time = get_current_time()\n",
    "deployment_start_time = datetime.now()\n",
    "\n",
    "deployment_id = response.id\n",
    "status = response.status\n",
    "update_json_file(\"env.json\", \"deployment_id\", deployment_id)\n",
    "print(\"Deployment Result:\\n\", response.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc074976",
   "metadata": {},
   "source": [
    "#### 5.Check the status and logs of the deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcd4c564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.Checking deployment status.\n",
      "Deployment is up and running now!\n",
      "Deployment duration: 0:00:47.743550 mins\n"
     ]
    }
   ],
   "source": [
    "print(\"4.Checking deployment status.\")\n",
    "deployment_url = f\"{base_url}/deployments/{deployment_id}\"\n",
    "deployment_log_url = f\"{deployment_url}/logs?start=\"\n",
    "interval_s = 20\n",
    "\n",
    "while status != \"RUNNING\" and status != \"DEAD\":\n",
    "    current_time = get_current_time()\n",
    "    #check deployment status\n",
    "    response = requests.get(url=deployment_url, headers=headers)\n",
    "    resp = response.json()\n",
    "    \n",
    "    status = resp['status']\n",
    "    print(f'...... Deployment Status at {current_time}......', flush=False)\n",
    "    print(f\"Deployment status: {status}\")\n",
    "\n",
    "    #retrieve deployment logs\n",
    "    response_log = requests.get(url=f\"{deployment_log_url}{last_check_time}\", headers=headers)\n",
    "    last_check_time = current_time\n",
    "    print(f\"Deployment logs: {response_log.text}\")\n",
    "\n",
    "    # Sleep for 60 secs to avoid overwhelming the API with requests\n",
    "    time.sleep(interval_s)\n",
    "\n",
    "deployment_end_time = datetime.now()\n",
    "duration_in_min = (deployment_end_time - deployment_start_time) / 60\n",
    "\n",
    "if status == \"RUNNING\":\n",
    "    print(\"Deployment is up and running now!\")\n",
    "else:\n",
    "    print(f\"Deployment {deployment_id} failed!\")   \n",
    "\n",
    "print(f\"Deployment duration: {duration_in_min} mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b92c17-76a1-4f88-a887-6356bb8ac1d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
