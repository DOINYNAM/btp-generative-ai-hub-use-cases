{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code snippet is authored by:<br>\n",
    "- Markus Fath https://github.com/fath-markus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how you can generate embedding vectors from \n",
    "* a (larger) number of documents/texts \n",
    "* stored in a HANA table \n",
    "* using generative-ai-hub-sdk\n",
    "* to access AI core services.\n",
    "\n",
    "There are four atomic functions\n",
    "* \"prepare_table\" adds a vector column to your table\n",
    "* \"read_documents\" pulls a batch of texts from your table\n",
    "* \"embed_documents\" sends one or multiple batches of text to an embedding function hosted on BTP\n",
    "* \"store_documents\" writes the embedding vectors to your table\n",
    "\n",
    "and an orchestrating function *\"read_embed_store_documents\"*, which runs the last three atomic functions in a loop.\n",
    "\n",
    "Prerequisites:\n",
    "- generative-ai-hub-sdk (1.2.0)\n",
    "- openAI ada deployment on AI Core in your BTP tenant\n",
    "\n",
    "See:<br>\n",
    "https://pypi.org/project/generative-ai-hub-sdk/\n",
    "https://help.sap.com/docs/sap-ai-core/sap-ai-core-service-guide/create-deployment-for-generative-ai-model-in-sap-ai-core\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModuleNotFoundError: No module named 'shapely'\n"
     ]
    }
   ],
   "source": [
    "# Connect to HANA using hana-ml\n",
    "from hana_ml.dataframe import ConnectionContext\n",
    "# cc = ConnectionContext(userkey='GR3', encrypt=True)\n",
    "cc= ConnectionContext(\n",
    "    address='[somehost].hanacloud.ondemand.com', \n",
    "    port='443', \n",
    "    user='[your user]', \n",
    "    password='[your password]', \n",
    "    encrypt=True\n",
    "    )\n",
    "connection = cc.connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from gen_ai_hub.proxy.langchain.openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings(proxy_model_name='text-embedding-ada-002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_table (schema_name:str, table_name:str, text_column:str):\n",
    "    \"\"\"\n",
    "        Adds a REAL_VECTOR column to a table.\n",
    "        @param schema_name <str>: Name of HANA schema to load vectors into\n",
    "        @param table_name <str>: Name of HANA table to load vectors into\n",
    "        @param text_column <str>: Name of text column of the HANA table\n",
    "    \"\"\"\n",
    "    now = str(datetime.now())\n",
    "    try:\n",
    "        curr = None\n",
    "        curr = cc.connection.cursor()\n",
    "        sql_command = f'''ALTER TABLE \"{schema_name}\".\"{table_name}\" \n",
    "            ADD (\"{text_column}_VECTOR\" REAL_VECTOR(1536) COMMENT 'embedding vector, generated from column {text_column} using openAI ada on {now}')'''\n",
    "        curr.execute(sql_command)\n",
    "        curr.close()\n",
    "    except Exception as exp:\n",
    "        print(f\"Could not alter table {table_name} due to {exp}\")\n",
    "    finally:\n",
    "        if curr != None:\n",
    "            curr.close()\n",
    "            pass\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_documents(schema_name:str, table_name:str, key_column:str, text_column:str, batch_size_read:int = 300):\n",
    "    \"\"\"\n",
    "        Read a batch of documents from a table, for which the vector column is NULL.\n",
    "        @param schema_name <str>: Name of HANA schema to load vectors into\n",
    "        @param table_name <str>: Name of HANA table to load vectors into\n",
    "        @param key_column <str>: Name of key column of the HANA table\n",
    "        @param text_column <str>: Name of text column of the HANA table\n",
    "        @param batch_size_read <int>: Number of documents to read in each iteration\n",
    "        @return pandas df\n",
    "    \"\"\"\n",
    "    sql_command = f''' SELECT \"{key_column}\", \"{text_column}\" FROM \"{schema_name}\".\"{table_name}\" \n",
    "        WHERE \"{text_column}_VECTOR\" IS NULL AND \"{text_column}\" IS NOT NULL AND LENGTH(\"{text_column}\") > 2 \n",
    "        LIMIT {batch_size_read} '''\n",
    "    hdf = cc.sql(sql_command)\n",
    "    return hdf.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_documents(df, key_column:str, text_column:str, batch_size_embed:int = 300):\n",
    "    \"\"\"\n",
    "        Function to embed documents from given dataframe.\n",
    "        @param df<pandas df>: dataframe with key and text\n",
    "        @param key_column <str>: Name of key column of the HANA table\n",
    "        @param text_column <str>: Name of text column of the HANA table\n",
    "        @param batch_size_embed <int>: Number of documents for each embedding batch\n",
    "    \"\"\"\n",
    "    # Extract documents and corresponding keys from df\n",
    "    docs = [(row[text_column], row[key_column]) for _, row in df.iterrows()]\n",
    "\n",
    "    # Truncate each text s.t. token length <= 8000... 1tok = 4 chars... 8000 tokens < 30k chars\n",
    "    doc_list = [e[0][:30000] for e in docs]\n",
    "\n",
    "    # Create the embeddings, pass batch_size and retry options to client\n",
    "    embedding = OpenAIEmbeddings(proxy_model_name='text-embedding-ada-002', chunk_size=batch_size_embed, max_retries=10)\n",
    "    return embedding.embed_documents(doc_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_vectors(schema_name:str, table_name:str, key_column:str, text_column:str, df, vector_list):\n",
    "    \"\"\"\n",
    "        Function to load vector embeddings into given HANA table.\n",
    "        @param schema_name <str>: Name of HANA schema to load vectors into\n",
    "        @param table_name <str>: Name of HANA table to load vectors into\n",
    "        @param key_column <str>: Name of key column of the HANA table\n",
    "        @param text_column <str>: Name of text column of the HANA table\n",
    "        @param df<pandas df>: dataframe with key and text\n",
    "        @param vector_list <list<list<float>>>: Document vectors\n",
    "    \"\"\"\n",
    "    docs = [(row[text_column], row[key_column]) for _, row in df.iterrows()]\n",
    "    # Prepare list of vectors and associated keys\n",
    "    rows = [(str(e), docs[idx][1]) for idx, e in enumerate(vector_list)]\n",
    "\n",
    "    # Load vectors in HANA table in transactional mode\n",
    "    cc.connection.setautocommit(False)\n",
    "    cursor = None\n",
    "    try:\n",
    "        cursor = cc.connection.cursor()\n",
    "        sql_command = f'''UPDATE \"{schema_name}\".\"{table_name}\" SET \"{text_column}_VECTOR\" = TO_REAL_VECTOR(?) WHERE \"{key_column}\" = ?'''\n",
    "        cursor.executemany(sql_command, rows)\n",
    "        cc.connection.commit()\n",
    "        print(f\"Docs inserted: \" + str(len(rows)))\n",
    "    except Exception as e:\n",
    "        cc.connection.rollback()\n",
    "        print(\"An error occurred:\", e)\n",
    "    finally:\n",
    "        if cursor != None:\n",
    "            cursor.close()\n",
    "            pass\n",
    "        pass\n",
    "\n",
    "    cc.connection.setautocommit(True)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs inserted: 5\n"
     ]
    }
   ],
   "source": [
    "# prepare_table('GRAPH_USER', 'TEST', 'SUMMARY');\n",
    "# df_docs = read_documents('GRAPH_USER', 'TEST', 'ID', 'SUMMARY', 5)\n",
    "# vector_list = embed_documents(df_docs, 'ID', 'SUMMARY', 2)\n",
    "# store_vectors('GRAPH_USER', 'TEST', 'ID', 'SUMMARY', df_docs, vector_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embed_store_documents(schema_name:str, table_name:str, key_column:str, text_column:str, batch_size_read:int, batch_size_embed:int):\n",
    "    \"\"\"\n",
    "        Function to generate vector embeddings for text stored in a HANA table.\n",
    "        @param schema_name <str>: schema of the HANA table\n",
    "        @param table_name <str>: name of the HANA table\n",
    "        @param key_column <str>: key column of the HANA table\n",
    "        @param text_column <str>: name of the column in which the text is stored\n",
    "        @param batch_size_read <int>: Number of documents to read in each iteration\n",
    "        @param batch_size_embed <int>: Number of documents for each embedding batch\n",
    "    \"\"\"\n",
    "    try:\n",
    "        prepare_table(schema_name=schema_name, table_name=table_name, text_column=text_column)\n",
    "    except:\n",
    "        pass\n",
    "    while True:\n",
    "        vector_list = []\n",
    "        number_of_new_docs = 0\n",
    "        df_docs = read_documents(schema_name=schema_name, table_name=table_name, key_column=key_column, text_column=text_column, batch_size_read=batch_size_read)\n",
    "        number_of_new_docs = len(df_docs)\n",
    "        if number_of_new_docs == 0:\n",
    "            print('All docs embedded.')\n",
    "            break\n",
    "        else:\n",
    "            print('Fetched {n} new docs.'.format(n=number_of_new_docs))\n",
    "            try:\n",
    "                print('Embedding {n} documents, using batch size {batch_size_embed}...'.format(n=number_of_new_docs, batch_size_embed=batch_size_embed))\n",
    "                vector_list = embed_documents(df=df_docs, key_column=key_column, text_column=text_column, batch_size_embed=batch_size_embed)\n",
    "                print('Done. Storing vectors in HANA...')\n",
    "                store_vectors(schema_name=schema_name, table_name=table_name, key_column=key_column, text_column=text_column, df=df_docs, vector_list=vector_list)\n",
    "                print('Done.')\n",
    "            finally:\n",
    "                pass\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 200 new docs.\n",
      "Embedding 200 documents, using batch size 100...\n",
      "Done. Storing vectors in HANA...\n",
      "Docs inserted: 200\n",
      "Done.\n",
      "Fetched 200 new docs.\n",
      "Embedding 200 documents, using batch size 100...\n",
      "Done. Storing vectors in HANA...\n",
      "Docs inserted: 200\n",
      "Done.\n",
      "All docs embedded.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "read_embed_store_documents(\n",
    "    schema_name='GRAPH_USER', \n",
    "    table_name='TEST', \n",
    "    key_column='ID', \n",
    "    text_column='SUMMARY', \n",
    "    batch_size_read=200,\n",
    "    batch_size_embed=100\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try a search\n",
    "def run_vector_search(query: str, metric=\"COSINE_SIMILARITY\", k=4):\n",
    "    if metric == 'L2DISTANCE':\n",
    "        sort = 'ASC'\n",
    "    else:\n",
    "        sort = 'DESC'\n",
    "    query_vector = embedding.embed_query(query)\n",
    "    sql = '''SELECT TOP {k} \"ID\", \"SUMMARY\", \"{metric}\"(\"SUMMARY_VECTOR\", TO_REAL_VECTOR('{qv}')) AS SIM\n",
    "        FROM \"GRAPH_USER\".\"TEST\"\n",
    "        ORDER BY \"SIM\" {sort}'''.format(k=k, metric=metric, qv=query_vector, sort=sort)\n",
    "    hdf = cc.sql(sql)\n",
    "    df_context = hdf.head(k).collect()\n",
    "    return df_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SUMMARY</th>\n",
       "      <th>SIM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3041353</td>\n",
       "      <td>Magic Journeys looked at the world through the...</td>\n",
       "      <td>0.785842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11378430</td>\n",
       "      <td>Financial disaster looms for Grand Fenwick whe...</td>\n",
       "      <td>0.773902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32671897</td>\n",
       "      <td>Leaving for vacation, Mickey Mouse and Pluto a...</td>\n",
       "      <td>0.767795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>878974</td>\n",
       "      <td>What appears to be a large saucer shaped meteo...</td>\n",
       "      <td>0.767222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2275930</td>\n",
       "      <td>When Stanley Putterman installs a brand new, s...</td>\n",
       "      <td>0.764737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26163035</td>\n",
       "      <td>The plot centers around restless thirtysomethi...</td>\n",
       "      <td>0.762663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1792785</td>\n",
       "      <td>A joint task force operation between the Drug ...</td>\n",
       "      <td>0.762617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32712254</td>\n",
       "      <td>Gabriel Nájera aka \"El Apenas\"  has been selli...</td>\n",
       "      <td>0.761622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26429769</td>\n",
       "      <td>Terrorists blow up a school bus in the Middle ...</td>\n",
       "      <td>0.761332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>168498</td>\n",
       "      <td>Launched in 1977, the Voyager 2 space probe ca...</td>\n",
       "      <td>0.760212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                            SUMMARY       SIM\n",
       "0   3041353  Magic Journeys looked at the world through the...  0.785842\n",
       "1  11378430  Financial disaster looms for Grand Fenwick whe...  0.773902\n",
       "2  32671897  Leaving for vacation, Mickey Mouse and Pluto a...  0.767795\n",
       "3    878974  What appears to be a large saucer shaped meteo...  0.767222\n",
       "4   2275930  When Stanley Putterman installs a brand new, s...  0.764737\n",
       "5  26163035  The plot centers around restless thirtysomethi...  0.762663\n",
       "6   1792785  A joint task force operation between the Drug ...  0.762617\n",
       "7  32712254  Gabriel Nájera aka \"El Apenas\"  has been selli...  0.761622\n",
       "8  26429769  Terrorists blow up a school bus in the Middle ...  0.761332\n",
       "9    168498  Launched in 1977, the Voyager 2 space probe ca...  0.760212"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'taxi luggage mexico motion sickness mosters nasa'\n",
    "df = run_vector_search(query = query, k = 10)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
